{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.5 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is already saved in the Workspace and can be accessed at the file path provided below.  Please run the next code cell without making any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# please do not modify the line below\n",
    "env = UnityEnvironment(file_name=\"/data/Banana_Linux_NoVis/Banana.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [ 1.          0.          0.          0.          0.84408134  0.          0.\n",
      "  1.          0.          0.0748472   0.          1.          0.          0.\n",
      "  0.25755     1.          0.          0.          0.          0.74177343\n",
      "  0.          1.          0.          0.          0.25854847  0.          0.\n",
      "  1.          0.          0.09355672  0.          1.          0.          0.\n",
      "  0.31969345  0.          0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agent while it is training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training the agent\n",
    "\n",
    "To train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agent while it is training.  However, **_after training the agent_**, you can download the saved model weights to watch the agent on your own machine! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_agent import Agent\n",
    "# init the agent\n",
    "agent = Agent(state_size=state_size, action_size=action_size, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Learning Algorithm\n",
    "\n",
    "The DQN algorithm is used to train the agent. It uses a fully connected neural network (NN) layers as a function approximator for the Q function. The NN consists of two hidden layers, each with 64 units. The input layer receives the states with 37 units and the output layer has four units for the possible actions.\n",
    "```\n",
    "QNetwork(\n",
    "  (fc1): Linear(in_features=37, out_features=64, bias=True)\n",
    "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
    "  (fc3): Linear(in_features=64, out_features=4, bias=True)\n",
    ") \n",
    "```\n",
    "\n",
    "The agents uses two identical architecture NNs to learn through interactions with the envrionment. The first, which is refered to as local QNetwork, is used to train the agent. The second, which is the target QNetwork, is used only in the error calculation to make the training process more stable.\n",
    "\n",
    "The algorithm performs and repeats two main tasks, which are:\n",
    "1. The sampling process:\n",
    "    - The agent chooses an action from the state using a given policy.\n",
    "        - The action is chosen using the $\\epsilon-greedy$ algorithm where the next best action has \n",
    "           the highest probabilty to be selected and low $\\epsilon$ probability for all other actions.\n",
    "    - The agent takes the action and receives new data from the environment. The data is in form of tuples `(next_state, reward, done)`. \n",
    "    - Store its experience tuple in a replay memory.\n",
    "    - Set state to the next state.\n",
    "2. The learning process:\n",
    "    - Obtain a random batch of tuples from the replay memory.\n",
    "    - Use the target QNetwork to get the target value.\n",
    "    ```\n",
    "    target = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "    ```\n",
    "    - Use the local QNetwork to get the expected value.\n",
    "    - Calculate the MSE between both returned values. \n",
    "    - Do an optimization step to change the weights of the local network.\n",
    "    - Do a soft update \n",
    "\n",
    "Near the end and if the agent learned successfully, it will choose the best possible action at each state.  \n",
    "\n",
    "The parameters I chose for the DQN are as follows:\n",
    "```\n",
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate \n",
    "UPDATE_EVERY = 4        # how often to update the network\n",
    "```\n",
    "\n",
    "And for the $\\epsilon$-greedy algorithm:\n",
    "```\n",
    "eps_start = 1.0         # starting value of epsilon\n",
    "eps_end = 0.01          # minimum value of epsilon\n",
    "eps_decay = 0.995       # multiplicative factor (per episode) for decreasing epsilon\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.95\n",
      "Episode 200\tAverage Score: 4.79\n",
      "Episode 300\tAverage Score: 7.36\n",
      "Episode 400\tAverage Score: 10.17\n",
      "Episode 496\tAverage Score: 13.01\n",
      "Environment solved in 396 episodes!\tAverage Score: 13.01\n",
      "Episode 497\tAverage Score: 13.01\n",
      "Environment solved in 397 episodes!\tAverage Score: 13.01\n",
      "Episode 498\tAverage Score: 13.09\n",
      "Environment solved in 398 episodes!\tAverage Score: 13.09\n",
      "Episode 499\tAverage Score: 13.09\n",
      "Environment solved in 399 episodes!\tAverage Score: 13.09\n",
      "Episode 500\tAverage Score: 13.24\n",
      "\n",
      "Environment solved in 400 episodes!\tAverage Score: 13.24\n",
      "Episode 503\tAverage Score: 13.28\n",
      "Environment solved in 403 episodes!\tAverage Score: 13.28\n",
      "Episode 504\tAverage Score: 13.33\n",
      "Environment solved in 404 episodes!\tAverage Score: 13.33\n",
      "Episode 505\tAverage Score: 13.35\n",
      "Environment solved in 405 episodes!\tAverage Score: 13.35\n",
      "Episode 511\tAverage Score: 13.37\n",
      "Environment solved in 411 episodes!\tAverage Score: 13.37\n",
      "Episode 514\tAverage Score: 13.41\n",
      "Environment solved in 414 episodes!\tAverage Score: 13.41\n",
      "Episode 515\tAverage Score: 13.42\n",
      "Environment solved in 415 episodes!\tAverage Score: 13.42\n",
      "Episode 516\tAverage Score: 13.43\n",
      "Environment solved in 416 episodes!\tAverage Score: 13.43\n",
      "Episode 538\tAverage Score: 13.43\n",
      "Environment solved in 438 episodes!\tAverage Score: 13.43\n",
      "Episode 566\tAverage Score: 13.46\n",
      "Environment solved in 466 episodes!\tAverage Score: 13.46\n",
      "Episode 567\tAverage Score: 13.48\n",
      "Environment solved in 467 episodes!\tAverage Score: 13.48\n",
      "Episode 568\tAverage Score: 13.52\n",
      "Environment solved in 468 episodes!\tAverage Score: 13.52\n",
      "Episode 577\tAverage Score: 13.53\n",
      "Environment solved in 477 episodes!\tAverage Score: 13.53\n",
      "Episode 578\tAverage Score: 13.53\n",
      "Environment solved in 478 episodes!\tAverage Score: 13.53\n",
      "Episode 579\tAverage Score: 13.55\n",
      "Environment solved in 479 episodes!\tAverage Score: 13.55\n",
      "Episode 586\tAverage Score: 13.61\n",
      "Environment solved in 486 episodes!\tAverage Score: 13.61\n",
      "Episode 587\tAverage Score: 13.65\n",
      "Environment solved in 487 episodes!\tAverage Score: 13.65\n",
      "Episode 588\tAverage Score: 13.72\n",
      "Environment solved in 488 episodes!\tAverage Score: 13.72\n",
      "Episode 589\tAverage Score: 13.76\n",
      "Environment solved in 489 episodes!\tAverage Score: 13.76\n",
      "Episode 590\tAverage Score: 13.81\n",
      "Environment solved in 490 episodes!\tAverage Score: 13.81\n",
      "Episode 596\tAverage Score: 13.83\n",
      "Environment solved in 496 episodes!\tAverage Score: 13.83\n",
      "Episode 599\tAverage Score: 13.86\n",
      "Environment solved in 499 episodes!\tAverage Score: 13.86\n",
      "Episode 600\tAverage Score: 13.75\n",
      "Episode 610\tAverage Score: 13.90\n",
      "Environment solved in 510 episodes!\tAverage Score: 13.90\n",
      "Episode 612\tAverage Score: 13.95\n",
      "Environment solved in 512 episodes!\tAverage Score: 13.95\n",
      "Episode 613\tAverage Score: 13.96\n",
      "Environment solved in 513 episodes!\tAverage Score: 13.96\n",
      "Episode 621\tAverage Score: 13.99\n",
      "Environment solved in 521 episodes!\tAverage Score: 13.99\n",
      "Episode 622\tAverage Score: 14.07\n",
      "Environment solved in 522 episodes!\tAverage Score: 14.07\n",
      "Episode 623\tAverage Score: 14.08\n",
      "Environment solved in 523 episodes!\tAverage Score: 14.08\n",
      "Episode 624\tAverage Score: 14.09\n",
      "Environment solved in 524 episodes!\tAverage Score: 14.09\n",
      "Episode 625\tAverage Score: 14.13\n",
      "Environment solved in 525 episodes!\tAverage Score: 14.13\n",
      "Episode 626\tAverage Score: 14.19\n",
      "Environment solved in 526 episodes!\tAverage Score: 14.19\n",
      "Episode 627\tAverage Score: 14.23\n",
      "Environment solved in 527 episodes!\tAverage Score: 14.23\n",
      "Episode 629\tAverage Score: 14.24\n",
      "Environment solved in 529 episodes!\tAverage Score: 14.24\n",
      "Episode 635\tAverage Score: 14.27\n",
      "Environment solved in 535 episodes!\tAverage Score: 14.27\n",
      "Episode 636\tAverage Score: 14.32\n",
      "Environment solved in 536 episodes!\tAverage Score: 14.32\n",
      "Episode 638\tAverage Score: 14.34\n",
      "Environment solved in 538 episodes!\tAverage Score: 14.34\n",
      "Episode 639\tAverage Score: 14.38\n",
      "Environment solved in 539 episodes!\tAverage Score: 14.38\n",
      "Episode 640\tAverage Score: 14.48\n",
      "Environment solved in 540 episodes!\tAverage Score: 14.48\n",
      "Episode 641\tAverage Score: 14.53\n",
      "Environment solved in 541 episodes!\tAverage Score: 14.53\n",
      "Episode 643\tAverage Score: 14.54\n",
      "Environment solved in 543 episodes!\tAverage Score: 14.54\n",
      "Episode 644\tAverage Score: 14.61\n",
      "Environment solved in 544 episodes!\tAverage Score: 14.61\n",
      "Episode 647\tAverage Score: 14.70\n",
      "Environment solved in 547 episodes!\tAverage Score: 14.70\n",
      "Episode 648\tAverage Score: 14.75\n",
      "Environment solved in 548 episodes!\tAverage Score: 14.75\n",
      "Episode 656\tAverage Score: 14.76\n",
      "Environment solved in 556 episodes!\tAverage Score: 14.76\n",
      "Episode 657\tAverage Score: 14.78\n",
      "Environment solved in 557 episodes!\tAverage Score: 14.78\n",
      "Episode 659\tAverage Score: 14.82\n",
      "Environment solved in 559 episodes!\tAverage Score: 14.82\n",
      "Episode 660\tAverage Score: 14.87\n",
      "Environment solved in 560 episodes!\tAverage Score: 14.87\n",
      "Episode 662\tAverage Score: 14.90\n",
      "Environment solved in 562 episodes!\tAverage Score: 14.90\n",
      "Episode 664\tAverage Score: 14.91\n",
      "Environment solved in 564 episodes!\tAverage Score: 14.91\n",
      "Episode 671\tAverage Score: 14.94\n",
      "Environment solved in 571 episodes!\tAverage Score: 14.94\n",
      "Episode 672\tAverage Score: 14.95\n",
      "Environment solved in 572 episodes!\tAverage Score: 14.95\n",
      "Episode 673\tAverage Score: 14.95\n",
      "Environment solved in 573 episodes!\tAverage Score: 14.95\n",
      "Episode 674\tAverage Score: 14.99\n",
      "Environment solved in 574 episodes!\tAverage Score: 14.99\n",
      "Episode 675\tAverage Score: 14.99\n",
      "Environment solved in 575 episodes!\tAverage Score: 14.99\n",
      "Episode 676\tAverage Score: 15.01\n",
      "Environment solved in 576 episodes!\tAverage Score: 15.01\n",
      "Episode 691\tAverage Score: 15.02\n",
      "Environment solved in 591 episodes!\tAverage Score: 15.02\n",
      "Episode 700\tAverage Score: 14.97\n",
      "Episode 701\tAverage Score: 15.04\n",
      "Environment solved in 601 episodes!\tAverage Score: 15.04\n",
      "Episode 702\tAverage Score: 15.04\n",
      "Environment solved in 602 episodes!\tAverage Score: 15.04\n",
      "Episode 706\tAverage Score: 15.04\n",
      "Environment solved in 606 episodes!\tAverage Score: 15.04\n",
      "Episode 708\tAverage Score: 15.09\n",
      "Environment solved in 608 episodes!\tAverage Score: 15.09\n",
      "Episode 709\tAverage Score: 15.15\n",
      "Environment solved in 609 episodes!\tAverage Score: 15.15\n",
      "Episode 714\tAverage Score: 15.16\n",
      "Environment solved in 614 episodes!\tAverage Score: 15.16\n",
      "Episode 715\tAverage Score: 15.18\n",
      "Environment solved in 615 episodes!\tAverage Score: 15.18\n",
      "Episode 717\tAverage Score: 15.21\n",
      "Environment solved in 617 episodes!\tAverage Score: 15.21\n",
      "Episode 718\tAverage Score: 15.21\n",
      "Environment solved in 618 episodes!\tAverage Score: 15.21\n",
      "Episode 719\tAverage Score: 15.23\n",
      "Environment solved in 619 episodes!\tAverage Score: 15.23\n",
      "Episode 720\tAverage Score: 15.29\n",
      "Environment solved in 620 episodes!\tAverage Score: 15.29\n",
      "Episode 745\tAverage Score: 15.37\n",
      "Environment solved in 645 episodes!\tAverage Score: 15.37\n",
      "Episode 746\tAverage Score: 15.42\n",
      "Environment solved in 646 episodes!\tAverage Score: 15.42\n",
      "Episode 752\tAverage Score: 15.42\n",
      "Environment solved in 652 episodes!\tAverage Score: 15.42\n",
      "Episode 777\tAverage Score: 15.42\n",
      "Environment solved in 677 episodes!\tAverage Score: 15.42\n",
      "Episode 778\tAverage Score: 15.44\n",
      "Environment solved in 678 episodes!\tAverage Score: 15.44\n",
      "Episode 779\tAverage Score: 15.51\n",
      "Environment solved in 679 episodes!\tAverage Score: 15.51\n",
      "Episode 780\tAverage Score: 15.52\n",
      "Environment solved in 680 episodes!\tAverage Score: 15.52\n",
      "Episode 781\tAverage Score: 15.52\n",
      "Environment solved in 681 episodes!\tAverage Score: 15.52\n",
      "Episode 782\tAverage Score: 15.54\n",
      "Environment solved in 682 episodes!\tAverage Score: 15.54\n",
      "Episode 783\tAverage Score: 15.54\n",
      "Environment solved in 683 episodes!\tAverage Score: 15.54\n",
      "Episode 794\tAverage Score: 15.55\n",
      "Environment solved in 694 episodes!\tAverage Score: 15.55\n",
      "Episode 798\tAverage Score: 15.57\n",
      "Environment solved in 698 episodes!\tAverage Score: 15.57\n",
      "Episode 799\tAverage Score: 15.60\n",
      "Environment solved in 699 episodes!\tAverage Score: 15.60\n",
      "Episode 800\tAverage Score: 15.57\n",
      "Episode 803\tAverage Score: 15.60\n",
      "Environment solved in 703 episodes!\tAverage Score: 15.60\n",
      "Episode 804\tAverage Score: 15.65\n",
      "Environment solved in 704 episodes!\tAverage Score: 15.65\n",
      "Episode 805\tAverage Score: 15.68\n",
      "Environment solved in 705 episodes!\tAverage Score: 15.68\n",
      "Episode 807\tAverage Score: 15.68\n",
      "Environment solved in 707 episodes!\tAverage Score: 15.68\n",
      "Episode 809\tAverage Score: 15.70\n",
      "Environment solved in 709 episodes!\tAverage Score: 15.70\n",
      "Episode 810\tAverage Score: 15.74\n",
      "Environment solved in 710 episodes!\tAverage Score: 15.74\n",
      "Episode 821\tAverage Score: 15.80\n",
      "Environment solved in 721 episodes!\tAverage Score: 15.80\n",
      "Episode 826\tAverage Score: 15.81\n",
      "Environment solved in 726 episodes!\tAverage Score: 15.81\n",
      "Episode 828\tAverage Score: 15.82\n",
      "Environment solved in 728 episodes!\tAverage Score: 15.82\n",
      "Episode 829\tAverage Score: 15.88\n",
      "Environment solved in 729 episodes!\tAverage Score: 15.88\n",
      "Episode 830\tAverage Score: 15.88\n",
      "Environment solved in 730 episodes!\tAverage Score: 15.88\n",
      "Episode 831\tAverage Score: 15.89\n",
      "Environment solved in 731 episodes!\tAverage Score: 15.89\n",
      "Episode 835\tAverage Score: 15.90\n",
      "Environment solved in 735 episodes!\tAverage Score: 15.90\n",
      "Episode 836\tAverage Score: 15.91\n",
      "Environment solved in 736 episodes!\tAverage Score: 15.91\n",
      "Episode 839\tAverage Score: 15.92\n",
      "Environment solved in 739 episodes!\tAverage Score: 15.92\n",
      "Episode 848\tAverage Score: 15.92\n",
      "Environment solved in 748 episodes!\tAverage Score: 15.92\n",
      "Episode 849\tAverage Score: 15.93\n",
      "Environment solved in 749 episodes!\tAverage Score: 15.93\n",
      "Episode 850\tAverage Score: 15.98\n",
      "Environment solved in 750 episodes!\tAverage Score: 15.98\n",
      "Episode 851\tAverage Score: 16.05\n",
      "Environment solved in 751 episodes!\tAverage Score: 16.05\n",
      "Episode 853\tAverage Score: 16.14\n",
      "Environment solved in 753 episodes!\tAverage Score: 16.14\n",
      "Episode 854\tAverage Score: 16.22\n",
      "Environment solved in 754 episodes!\tAverage Score: 16.22\n",
      "Episode 857\tAverage Score: 16.22\n",
      "Environment solved in 757 episodes!\tAverage Score: 16.22\n",
      "Episode 858\tAverage Score: 16.24\n",
      "Environment solved in 758 episodes!\tAverage Score: 16.24\n",
      "Episode 859\tAverage Score: 16.31\n",
      "Environment solved in 759 episodes!\tAverage Score: 16.31\n",
      "Episode 900\tAverage Score: 15.75\n",
      "Episode 1000\tAverage Score: 15.70\n",
      "Episode 1100\tAverage Score: 15.24\n",
      "Episode 1200\tAverage Score: 15.56\n",
      "Episode 1300\tAverage Score: 15.90\n",
      "Episode 1400\tAverage Score: 15.80\n",
      "Episode 1500\tAverage Score: 15.75\n",
      "Episode 1600\tAverage Score: 15.63\n",
      "Episode 1700\tAverage Score: 15.58\n",
      "Episode 1800\tAverage Score: 15.85\n",
      "Episode 1900\tAverage Score: 15.38\n",
      "Episode 2000\tAverage Score: 15.51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f87d5223b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    best_score = 13.0\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        state = env_info.vector_observations[0]\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            env_info = env.step(action)[brain_name]\n",
    "            \n",
    "            next_state = env_info.vector_observations[0]\n",
    "            reward = env_info.rewards[0]\n",
    "            done = env_info.local_done[0]\n",
    "            \n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=best_score:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            best_score = np.mean(scores_window)\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "    return scores\n",
    "\n",
    "scores = dqn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the agent was able to solve the environment in episode 396. But it achieved its best score in episode 759."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f87d5223550>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the model has a great score and performance, but it can be further improved by trying other algorithms like:\n",
    "- Double DQN\n",
    "- Prioritized Experience Replay\n",
    "- Dueling DQN\n",
    "- Pixel Based Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
